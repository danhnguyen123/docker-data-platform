version: "3"
x-spark-common:
  &spark-common
  env_file:
      - ./.env.spark
  extra_hosts:
    - "host.docker.internal:host-gateway"
  environment:
    &spark-common-env
    - SPARK_RPC_AUTHENTICATION_ENABLED=no
    - SPARK_RPC_ENCRYPTION_ENABLED=no
    - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
    - SPARK_SSL_ENABLED=no
  networks:
    - data-network

services:
## Spark Standalone ##
  spark-master:
    <<: *spark-common
    build:
      context: .
      dockerfile: Dockerfile
    image: spark-image
    container_name: spark-master
    hostname: spark-master
    command: bash -c "sbin/start-master.sh -p 7077"
    environment:
      - SPARK_LOCAL_IP=spark-master
    ports:
      - 4040:4040
      - 7077:7077
      - 8008:8080
    volumes:
      - spark-logs:/opt/spark/spark-events
      - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      # - ./conf/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ../../workspace:/opt/workspace

  spark-worker:
    <<: *spark-common
    image: spark-image
    command: bash -c "sbin/start-worker.sh spark://spark-master:7077"
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
    volumes:
      - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ../../workspace:/opt/workspace
    depends_on:
      - spark-master

  spark-history-server:
    <<: *spark-common
    image: spark-image
    container_name: spark-history
    command: bash -c "sbin/start-history-server.sh"
    volumes:
      - spark-logs:/opt/spark/spark-events
    ports:
      - 18080:18080

  spark-thrift-server:
    image: spark-image
    container_name: spark-thrift-server
    profiles: ["thrift"]
    volumes:
      - spark-logs:/opt/spark/spark-events
    ports:
      - 4041:4040
      - 10000:10000
      - 10002:10002
    command: bash -c "
      sleep 10 && sbin/start-thriftserver.sh
                --driver-java-options '-Dhive.metastore.uris=thrift://hive-metastore:9083'
                --master spark://spark-master:7077
                --executor-cores 1
                --executor-memory 2G
                --total-executor-cores 1"
    depends_on:
      - spark-master

  spark-notebook:
    <<: *spark-common
    build:
      context: .
      dockerfile: ./jupyterlab.Dockerfile
    image: spark-notebook
    container_name: spark-notebook
    profiles: ["notebook"]
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=admin --NotebookApp.password="$${JUPYTERLAB_PASSWORD}"
    volumes:
      - spark-logs:/opt/spark/spark-events
      - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ../../workspace:/opt/workspace
    ports:
      - 8888:8888
      - 4042:4040
    depends_on:
      - spark-master

volumes:
  spark-logs:

networks:
  data-network:
    external: true